{"cells":[{"metadata":{},"cell_type":"markdown","source":"Intro notebook on working with JSON data from CORD-19 dataset. Reviews some common data access and transformations to get JSON data into a format were it can be analyzed through pandas and NLP tools.\n\n* Load JSON for one of the records into a variable\n* Access various element in JSON as python dictionary\n* Use glob to access all files in non_comm_use_subset directory\n* Use a loop to access elements of JSON (body_text and id)\n* Convert to a pandas dataframe\n* Access Google Cloup Platform NLP APIs to assign sentiment and categories to each record in the directory\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import json","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Open one of the files in the noncomm_use_subset directory and load the JSON into a dictionary object","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/CORD-19-research-challenge/document_parses/pdf_json/6f192000b0e87fe2c55632441655de31c61596c4.json') as json_file:\n    data = json.load(json_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take a look at the top level keys of the dictionary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Access the text for some of the elements of the document, abstract and body_text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of these dictionary elements map to list (for example, both abstract and body_text are split into a list of text fields)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['abstract']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['abstract'][0]['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['body_text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data['body_text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Access each field for body text in a loop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for bt in data['body_text']:\n    print(bt['text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far we've accessed the data for one document - next, let's write a loop to access all the documents in a directory. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"json_files = glob.glob('/kaggle/input/CORD-19-research-challenge/document_parses/pdf_json/*.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"json_files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(json_files)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I sometimes find it easier to work with tabular data in pandas rather than parsing JSON documents. One way to do this is to parse the documents in a loop, store the results to lists, and build a pandas dataframe from the lists. \n\nHere, we'll build a pandas dataframe with the paper id and the full body text. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"paper_texts = []\npaper_ids = []\n\ni = 0\n\nfor jf in json_files[:100]:\n    with open(jf) as json_file:\n        data = json.load(json_file)\n    \n    paper_ids.append(data['paper_id'])\n    \n    paper_text = []\n    for b in data['body_text']:\n        paper_text.append(b['text'])\n    \n    paper_texts.append(\" \".join(paper_text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(paper_texts))\nprint(len(paper_ids))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"paper_id\": paper_ids, \"text\": paper_texts})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[2]['text']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For a bit of analysis, we'll use the Google Cloud NLP api to assign categories and sentiment scores to each paper. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from googleapiclient.discovery import build","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import getpass\nAPIKEY = getpass.getpass()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lservice = build('language', 'v1', developerKey=APIKEY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories_response = lservice.documents().classifyText(\n  body={\n    'document': {\n      'type': 'PLAIN_TEXT',\n      'content':  df.iloc[2]['text'] }\n}).execute()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories_response","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_response = lservice.documents().analyzeSentiment(\n    body={\n      'document': {\n        'type': 'PLAIN_TEXT',\n        'content': df.iloc[2]['text']\n    }\n  }).execute()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_response","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}